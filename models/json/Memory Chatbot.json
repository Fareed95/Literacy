{
  "id": "97936f99-0b10-406d-b8f9-30fa4ed66a59",
  "data": {
    "nodes": [
      {
        "data": {
          "id": "ChatInput-cjWJK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what is my name"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 319,
        "id": "ChatInput-cjWJK",
        "position": {
          "x": 2321.5543981677606,
          "y": 374.0457826421628
        },
        "positionAbsolute": {
          "x": 2321.5543981677606,
          "y": 374.0457826421628
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-VIgwN",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 319,
        "id": "ChatOutput-VIgwN",
        "position": {
          "x": 3103.384633336826,
          "y": 776.4408905693839
        },
        "positionAbsolute": {
          "x": 3103.384633336826,
          "y": 776.4408905693839
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-T4Muo",
          "node": {
            "description": "# Memory Chatbot\n\nA flexible chatbot implementation featuring advanced conversation memory capabilities. This serves as a foundational tool for building chat experiences with persistent context.\n\n## Core Components\n\n1. **Chat Input**\n   - Accepts user messages\n   - Configures conversation storage\n   - Tracks session identity\n\n2. **Chat Memory**\n   - Stores and retrieves up to 100 previous messages\n   - Maintains conversation context\n   - Tracks separate chat sessions\n   - Preserves sender information and message order\n\n3. **Prompt**\n   - Creates dynamic prompt templates\n   - Integrates memory into conversation flow\n\n4. **OpenAI**\n   - Processes user input with context\n   - Accesses conversation history\n   - Includes options for model configuration and API key setup\n\n5. **Chat Output**\n   - Displays formatted responses\n   - Maintains conversation flow\n   - Syncs with memory storage\n\n## Memory Features\n\n- Stores message history\n- Plans conversation trajectory\n- Differentiates between chat sessions\n- Preserves sender and message metadata\n\n## Quick Start\n\n1. **Initialize** with a clear session ID\n2. **Enter** message in Chat Input\n3. **AI Processes** with context from memory\n4. **Response** appears in Chat Output\n5. Context remains available for follow-ups\n\nThis robust system demonstrates thorough memory integration with minimal complexity. ðŸ§ ðŸ’¬\n",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 736,
        "id": "note-T4Muo",
        "position": {
          "x": 1512.8976594415833,
          "y": 312.9558305744385
        },
        "positionAbsolute": {
          "x": 1512.8976594415833,
          "y": 312.9558305744385
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 736,
          "width": 382
        },
        "type": "noteNode",
        "width": 382
      },
      {
        "data": {
          "id": "note-jRosq",
          "node": {
            "description": "## Get Your OpenAI API Key\n\n**Steps**:\n\n1. **Visit** [OpenAI's API Key Page](https://platform.openai.com/api-keys).\n\n2. **Log In/Sign Up**:\n   - Log in or create a new OpenAI account.\n\n3. **Generate API Key**:\n   - Click \"Create New Secret Key\" to obtain your key.\n\n4. **Store Your Key Securely**:\n   - Note it down as it will only display once.\n\n5. **Enter API Key**:\n   - Input your key in the OpenAI API Key field within the component setup.\n\nKeep your key safe and manage it responsibly!",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "rose"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 325,
        "id": "note-jRosq",
        "position": {
          "x": 2727.7060397092964,
          "y": 115.42518754847691
        },
        "positionAbsolute": {
          "x": 2727.7060397092964,
          "y": 115.42518754847691
        },
        "selected": false,
        "type": "noteNode",
        "width": 325
      },
      {
        "data": {
          "id": "Memory-T2BgA",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory",
            "documentation": "",
            "edited": false,
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "retrieve_messages",
                "name": "messages",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Text",
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom langflow.custom import Component\nfrom langflow.field_typing import BaseChatMemory\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import LCBuiltinChatMemory, get_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Text\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        chat_memory = self.memory or LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "type": "Memory"
        },
        "dragging": false,
        "height": 349,
        "id": "Memory-T2BgA",
        "position": {
          "x": 1947.7805399474369,
          "y": 766.1115984799474
        },
        "positionAbsolute": {
          "x": 1947.7805399474369,
          "y": 766.1115984799474
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "Prompt-AgQx8",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "memory": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "memory",
                "display_name": "memory",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a helpful ai genz mentor that answer students questions based on the the the json format provided to you. Please note not answer any question beyond this skill provided to you.. please make your output with beautiful genz slangs and even if the user going out of the topic motivates them with this beautiful genz slangs. \n\nskill data in json - {skill}\n\nUse markdown to format your answer, properly embedding images and urls.\n\nHistory: \n\n{memory}\n"
              },
              "skill": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{\n  \"component\": {\n    \"description\": \"Learn the fundamentals of Express.js, including routing, middleware, and template engines.\",\n    \"document\": \"https://expressjs.com/en/guide/routing.html\",\n    \"embed_url\": \"https://www.youtube.com/embed/SccSCuHhOw0\",\n    \"name\": \"Express.js Basics\",\n    \"test_series\": [\n      {\n        \"answer\": \"To create a new route\",\n        \"options\": [\n          \"To create a new route\",\n          \"To delete an existing route\",\n          \"To update an existing route\",\n          \"To get an existing route\"\n        ],\n        \"question\": \"What is the primary use of the 'app.get' method in Express.js?\"\n      },\n      {\n        \"answer\": \"app.use is used for middleware, while app.get is used for routing\",\n        \"options\": [\n          \"app.use is used for routing, while app.get is used for middleware\",\n          \"app.use is used for middleware, while app.get is used for routing\",\n          \"app.use is used for template engines, while app.get is used for routing\",\n          \"app.use is used for routing, while app.get is used for template engines\"\n        ],\n        \"question\": \"What is the difference between 'app.use' and 'app.get' in Express.js?\"\n      },\n      {\n        \"answer\": \"To render a template engine\",\n        \"options\": [\n          \"To render a template engine\",\n          \"To send a response to the client\",\n          \"To redirect to a new route\",\n          \"To handle an error\"\n        ],\n        \"question\": \"What is the purpose of the 'res.render' method in Express.js?\"\n      }\n    ]\n  },\n  \"id\": 2,\n  \"name\": \"MERN\"\n}",
                "fileTypes": [],
                "file_path": "",
                "name": "skill",
                "display_name": "skill",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "skill",
                "memory"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 430,
        "id": "Prompt-AgQx8",
        "position": {
          "x": 2297.685950759621,
          "y": 850.4571095916292
        },
        "positionAbsolute": {
          "x": 2297.685950759621,
          "y": 850.4571095916292
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "id": "GroqModel-v1qB4",
        "type": "genericNode",
        "position": {
          "x": 2724.7525608892006,
          "y": 536.2144772450645
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom langflow.base.models.groq_constants import GROQ_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n    name = \"GroqModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        SecretStrInput(name=\"groq_api_key\", display_name=\"Groq API Key\", info=\"API key for the Groq API.\"),\n        MessageTextInput(\n            name=\"groq_api_base\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n            value=\"https://api.groq.com\",\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            value=0.1,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GROQ_MODELS,\n            value=\"llama-3.1-8b-instant\",\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def get_models(self) -> list[str]:\n        api_key = self.groq_api_key\n        base_url = self.groq_api_base or \"https://api.groq.com\"\n        url = f\"{base_url}/openai/v1/models\"\n\n        headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            model_list = response.json()\n            return [model[\"id\"] for model in model_list.get(\"data\", [])]\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return GROQ_MODELS\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"groq_api_key\", \"groq_api_base\", \"model_name\"}:\n            models = self.get_models()\n            build_config[\"model_name\"][\"options\"] = models\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_groq import ChatGroq\n        except ImportError as e:\n            msg = \"langchain-groq is not installed. Please install it with `pip install langchain-groq`.\"\n            raise ImportError(msg) from e\n\n        groq_api_key = self.groq_api_key\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        groq_api_base = self.groq_api_base\n        n = self.n\n        stream = self.stream\n\n        return ChatGroq(\n            model=model_name,\n            max_tokens=max_tokens or None,\n            temperature=temperature,\n            base_url=groq_api_base,\n            n=n or 1,\n            api_key=SecretStr(groq_api_key).get_secret_value(),\n            streaming=stream,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "groq_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "groq_api_base",
                "value": "https://api.groq.com",
                "display_name": "Groq API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "groq_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "groq_api_key",
                "value": "",
                "display_name": "Groq API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API key for the Groq API.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Output Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "distil-whisper-large-v3-en",
                  "gemma2-9b-it",
                  "gemma-7b-it",
                  "llama3-groq-70b-8192-tool-use-preview",
                  "llama3-groq-8b-8192-tool-use-preview",
                  "llama-3.1-70b-versatile",
                  "llama-3.1-8b-instant",
                  "llama-3.2-1b-preview",
                  "llama-3.2-3b-preview",
                  "llama-3.2-11b-vision-preview",
                  "llama-3.2-90b-vision-preview",
                  "llama-guard-3-8b",
                  "llama3-70b-8192",
                  "llama3-8b-8192",
                  "mixtral-8x7b-32768",
                  "whisper-large-v3",
                  "whisper-large-v3-turbo"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.1-8b-instant",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the model to use.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.2,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Groq.",
            "icon": "Groq",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Groq",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "groq_api_key",
              "groq_api_base",
              "max_tokens",
              "temperature",
              "n",
              "model_name",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "GroqModel",
          "id": "GroqModel-v1qB4"
        },
        "selected": false,
        "width": 320,
        "height": 668,
        "positionAbsolute": {
          "x": 2724.7525608892006,
          "y": 536.2144772450645
        },
        "dragging": false
      },
      {
        "id": "TextInput-Ob80U",
        "type": "genericNode",
        "position": {
          "x": 1596.2259009604768,
          "y": 1143.874846739994
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "fareed",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "TextInput",
          "id": "TextInput-Ob80U"
        },
        "selected": true,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1596.2259009604768,
          "y": 1143.874846739994
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-T2BgA",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "Prompt-AgQx8",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-T2BgA{Å“dataTypeÅ“:Å“MemoryÅ“,Å“idÅ“:Å“Memory-T2BgAÅ“,Å“nameÅ“:Å“messages_textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-AgQx8{Å“fieldNameÅ“:Å“memoryÅ“,Å“idÅ“:Å“Prompt-AgQx8Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "source": "Memory-T2BgA",
        "sourceHandle": "{Å“dataTypeÅ“:Å“MemoryÅ“,Å“idÅ“:Å“Memory-T2BgAÅ“,Å“nameÅ“:Å“messages_textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-AgQx8",
        "targetHandle": "{Å“fieldNameÅ“:Å“memoryÅ“,Å“idÅ“:Å“Prompt-AgQx8Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false
      },
      {
        "source": "ChatInput-cjWJK",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-cjWJKÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "GroqModel-v1qB4",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GroqModel-v1qB4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-cjWJK",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-cjWJK{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-cjWJKÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-GroqModel-v1qB4{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-AgQx8",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-AgQx8Å“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "GroqModel-v1qB4",
        "targetHandle": "{Å“fieldNameÅ“:Å“system_messageÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "GroqModel-v1qB4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-AgQx8",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-AgQx8{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-AgQx8Å“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-GroqModel-v1qB4{Å“fieldNameÅ“:Å“system_messageÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      },
      {
        "source": "GroqModel-v1qB4",
        "sourceHandle": "{Å“dataTypeÅ“:Å“GroqModelÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatOutput-VIgwN",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-VIgwNÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-VIgwN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GroqModel",
            "id": "GroqModel-v1qB4",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GroqModel-v1qB4{Å“dataTypeÅ“:Å“GroqModelÅ“,Å“idÅ“:Å“GroqModel-v1qB4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-VIgwN{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-VIgwNÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      },
      {
        "source": "TextInput-Ob80U",
        "sourceHandle": "{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Memory-T2BgA",
        "targetHandle": "{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“Memory-T2BgAÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "Memory-T2BgA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-Ob80U",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-Ob80U{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Memory-T2BgA{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“Memory-T2BgAÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "TextInput-Ob80U",
        "sourceHandle": "{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatInput-cjWJK",
        "targetHandle": "{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“ChatInput-cjWJKÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "ChatInput-cjWJK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-Ob80U",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-Ob80U{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatInput-cjWJK{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“ChatInput-cjWJKÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "TextInput-Ob80U",
        "sourceHandle": "{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatOutput-VIgwN",
        "targetHandle": "{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“ChatOutput-VIgwNÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "ChatOutput-VIgwN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-Ob80U",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-Ob80U{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-Ob80UÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-VIgwN{Å“fieldNameÅ“:Å“session_idÅ“,Å“idÅ“:Å“ChatOutput-VIgwNÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      }
    ],
    "viewport": {
      "x": -1034.972663665154,
      "y": -324.1690594434999,
      "zoom": 0.7047703354445247
    }
  },
  "description": "Create a chatbot that saves and references previous messages, enabling the model to maintain context throughout the conversation.",
  "name": "Memory Chatbot",
  "last_tested_version": "1.1.1",
  "endpoint_name": null,
  "is_component": false
}